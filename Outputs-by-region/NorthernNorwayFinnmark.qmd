---
title: "Northern Norway and Finnmark biomass and catches"
format: html
embed-resources: true
editor: visual
---

## Goal

To collect, compile, and analyze fish community catch data, landings, and biomass estimates from a variety of sources. This includes integrating datasets from fisheries catch statistics and scientific surveys to quantify catch and biomass across different regions. The goal is to develop a dataset, including both Large Marine Ecosystems (LMEs) and Marine Ecoregions (MEs), that facilitates the validation and calibration of marine ecosystem models with a focus on fish and fisheries.

## Data types

-   Catches and landings by ME from Sea Around us Data (version 50.1)

-   Catches and landings from Watson (2017, [10.1038/sdata.2017.39](10.1038/sdata.2017.39)) aggregated to ME-scale

-   ICES stock assessment database (ICES Stock Assessment Graphs database, extracted 2023/09. ICES, Copenhagen."

-   Fisheries independent bottom trawl survey data of fish biomass corrected with a catchability factor and standardized by swept area - DOI [10.5281/zenodo.7992513](https://doi.org/10.5281/zenodo.7992513)

```{r}
#| echo: true
#| warning: false
#| message: false
#| error: false

# define values
ME_name   <- "Northern Norway and Finnmark"
Start_year <- 1990
End_year <- 2015

# load libraries
library(ggplot2)
library(dplyr)
library(sf)
library(tidyverse)
library(tidyr)
library(sdmTMB)
```

## Catches and landings

Time series of marine fish catches and landings were estimated by ME using data from SAU and Watson (2017). The catch estimates encompass landings, discards, and approximations of illegal, unregulated, and unreported (IUU) catches.

The landings figure includes a time series of landings for all assessed stocks for which total biomass or spawning stock biomass estimates are available. Some of these stocks have spatial assessment areas that only partially overlap with the region. In such cases, landings were proportionally adjusted based on the degree of overlap. For each stock, landings were allocated only to areas where the species occur. For example, landings from stocks inhabiting shallow waters were not assigned to deeper areas. This allocation was based on distribution maps from AquaMaps.

```{r Catch & Land. }
# -----------------------------------------------------
# load SAU data
SAU <- read.csv("../Data/SAU/SAU_NorthernNorway_Finnmark_ME.csv")
SAU <- subset(SAU,SAU$year %in% Start_year:End_year)
SAU <- subset(SAU, !(SAU$functional_group %in% c("Shrimps","Other demersal invertebrates","Cephalopods","Lobsters, crabs","Krill")))

# get total catch
Catch_SAU <- aggregate(tonnes~year,data=SAU,FUN=sum)
colnames(Catch_SAU) <- c("Year","Tonnes")

# get landings
Land_SAU <- subset(SAU,SAU$catch_type == "Landings")
Land_SAU <- aggregate(tonnes~year,data=Land_SAU,FUN=sum)
colnames(Land_SAU) <- c("Year","Tonnes")

# -----------------------------------------------------
# load Watson
load("../Data/Watson/NorwayFinnME.RData")
WAT <- subset(tot,tot$Year %in% Start_year:End_year)
Catch_WAT <- WAT[,c("Year","Total_catch")]
colnames(Catch_WAT) <- c("Year","Tonnes")
Land_WAT <- WAT[,c("Year","Total_reported")]
colnames(Land_WAT) <- c("Year","Tonnes")

# -----------------------------------------------------
# load stock assessment reported landings
load("../Data/ICES_stocks/AquaMaps_occurence_ICES_stocks.Rdata")
load("../Data/ICES_stocks/Assessment_spatially_allocated.Rdata")
STO <- subset(grid,grid$ME == ME_name)
STO <- subset(totdat,totdat$id %in% STO$id & totdat$Year %in% Start_year:End_year)
STO$Catch <- ifelse(is.na(STO$Catch),STO$Landings,STO$Catch)
STO$Landings <- ifelse(is.na(STO$Landings),STO$Catch,STO$Landings)

Catch_STO <- aggregate(Catch~Year,data=STO,FUN=sum)
colnames(Catch_STO) <- c("Year","Tonnes")
Land_STO <- aggregate(Landings~Year,data=STO,FUN=sum)
colnames(Land_STO) <- c("Year","Tonnes")

par(mar = c(5, 4, 3, 3),mfrow=c(1,2))
plot(Catch_SAU$Tonnes/10^6~Catch_SAU$Year,ylim=c(0,7),type="l",col="red",lwd=2,
     ylab="Catch (million tonnes y-1)",las=1,xlab="Year",main="Catch",lty=2)
lines(Catch_WAT$Tonnes/10^6~Catch_WAT$Year,col="blue",lwd=2,lty=3)
lines(Catch_STO$Tonnes/10^6~Catch_STO$Year,col="black",lwd=2,lty=1)
legend(Start_year,7.3, legend=c("SAU", "Watson", "Ass. stocks"), col=c("red", "blue","black"), lty=c(2,3,1), cex=1,y.intersp = 1,x.intersp = .5,seg.len=1, box.lty=0,bg="transparent")

plot(Land_SAU$Tonnes/10^6~Land_SAU$Year,ylim=c(0,7),type="l",col="red",lwd=2,
     ylab="Landings (million tonnes y-1)",las=1,xlab="Year",main="Landings",lty=2)
lines(Land_WAT$Tonnes/10^6~Land_WAT$Year,col="blue",lwd=2,lty=3)
lines(Land_STO$Tonnes/10^6~Land_STO$Year,col="black",lwd=2,lty=1)


```

## Biomass of assessed stocks

Time series of assessed fish biomass were estimated by LME using data from scientific trawl surveys and based on information for all assessed stocks for which total biomass or spawning stock biomass estimates are available. Some of these stocks have spatial assessment areas that only partially overlap with the region. In such cases, biomass were proportionally adjusted based on the degree of overlap. For each stock, biomass were allocated only to areas where the species occur. For example, biomass from stocks inhabiting shallow waters were not assigned to deeper areas. This allocation was based on distribution maps from AquaMaps.

The biomass estimates from scientific surveys were corrected for differences in sampling area and trawl gear catchability (Maureaud et al. 2024; van Denderen et al. 2023). We estimated both total biomass and biomass per unit area using the GLMMTMB package. We only included species for which a stock assessment is provided.

```{r Stock bio.}
#| warning: false
#| message: false
#| error: false

# -----------------------------------------------------
# load biomass from stock assessments
load("../Data/ICES_stocks/AquaMaps_occurence_ICES_stocks.Rdata")
load("../Data/ICES_stocks/Assessment_spatially_allocated.Rdata")
MEgrid <- subset(grid,grid$ME == ME_name)
STO <- subset(totdat,totdat$id %in% MEgrid$id & 
                totdat$Year %in% Start_year:End_year)

# add the area to be able to estimate biomass in mass per area
STO <- cbind(STO,grid[match(STO$id,grid$id), c("area_sqkm","ocean_sqkm","depth")])

# for some stocks, uncertainty in Tbio is not provide; put median 
STO$Tbio_low <- ifelse(is.na(STO$Tbio_low),STO$Tbio,STO$Tbio_low)
STO$Tbio_high <- ifelse(is.na(STO$Tbio_high),STO$Tbio,STO$Tbio_high)

# for some only SSB is provided; add to Tbio
STO$SSB_low <- ifelse(is.na(STO$SSB_low),STO$SSB,STO$SSB_low)
STO$SSB_high <- ifelse(is.na(STO$SSB_high),STO$SSB,STO$SSB_high)
STO$Tbio <- ifelse(is.na(STO$Tbio),STO$SSB,STO$Tbio)
STO$Tbio_low <- ifelse(is.na(STO$Tbio_low),STO$SSB_low,STO$Tbio_low) 
STO$Tbio_high <- ifelse(is.na(STO$Tbio_high),STO$SSB_high,STO$Tbio_high)

# estimate total biomass and get total area
STO <- subset(STO,STO$depth >= -500)
Bio_STO <- aggregate(cbind(Tbio_low, Tbio, Tbio_high)~Year,data=STO,FUN=sum)
Bio_STO$area <- sum(MEgrid$ocean_sqkm[MEgrid$depth >= -500])

# -----------------------------------------------------
# load scientific survey biomass
load("../Data/Trawl_survey/Surveys_hauls_species_LMEs_MEs.RData")
Reg <- subset(trawl,trawl$ME == ME_name & 
                trawl$Year %in% Start_year:End_year)

# match all hauls with the MEgrid id
hauls <- Reg[!duplicated(Reg$Haul_id), ]
hauls <- st_as_sf(hauls, coords = c("Longitude", "Latitude"), crs = 4326)
ha_grid <- st_intersects(hauls,MEgrid)
ha_grid <- as.data.frame(ha_grid)
ha_grid <- data.frame(Haul_id = hauls$Haul_id[ha_grid[,1]],uni_id = MEgrid$id[ha_grid[,2]])

# load ices/fao species code
ASFIS <- read.csv("../Data/ICES_stocks/ASFIS_sp_2025.csv")

# select all species that have a stock assessment in the area
spec <- stringr::str_sub(colnames(MEgrid), 1, 3)
spec <- setdiff(spec, c("id", "lan","geo","are","oce","LME","dep","ME"))
spec <- unique(spec)

# now get for each haul and species, if there is a match with a stock
Reg$Stock <- 0 # no match = 0, match = 1

for (j in 1:length(spec)) {
  specname   <- ASFIS$Scientific_Name[which(toupper(spec[j]) == ASFIS$Alpha3_Code)]
  MEgrid_df <- st_drop_geometry(MEgrid)
  cols_with_spec <- grep(paste0("^", spec[j]), colnames(MEgrid_df))
  if (length(cols_with_spec) > 1) {
    MEgrid_df$new <- rowSums(MEgrid_df[, cols_with_spec])
  } else {
    MEgrid_df$new <- MEgrid_df[, cols_with_spec]
  }
  
  areaspec <- subset(MEgrid_df, MEgrid_df$new == 1)
  gridspec <- subset(ha_grid, ha_grid$uni_id %in% areaspec$id)
  Reg$Stock <-  ifelse(Reg$Name == specname & Reg$Haul_id %in%  gridspec$Haul_id,
                       1, Reg$Stock)
}

Reg$F_type <- ifelse(Reg$F_type =="pel" & Reg$Stock == 1,"pel_stock", Reg$F_type)
Reg$F_type <- ifelse(Reg$F_type =="dem" & Reg$Stock == 1,"dem_stock", Reg$F_type)

# Group and summarize
Reg <- Reg %>% 
  group_by(Haul_id, Survey_Region, Gear, Year, Month, Longitude, 
           Latitude, Bottom_depth, F_type, uniq, ME) %>%
  summarize(kg_km2_corrected = sum(kg_km2_corrected, na.rm = TRUE), 
            .groups = 'drop') %>%
  dplyr::select(Haul_id, Survey_Region, Gear, Year, Month, Longitude, 
           Latitude, Bottom_depth, F_type, uniq, ME, kg_km2_corrected) %>%
  as.data.frame()

# a few hauls have negative values
Reg$Bottom_depth <- abs(Reg$Bottom_depth)

# Get estimate by haul
Reg <- Reg %>%
  pivot_wider(names_from = F_type, 
              values_from = kg_km2_corrected, values_fill = 0) %>% 
    mutate(Total_kg_km2 = rowSums(select(., c("dem","pel","pel_stock",
                                              "dem_stock")), na.rm = TRUE)) %>%
  as.data.frame()

# and plot surveyed locations by year
ggplot(Reg, aes(x = Longitude, y = Latitude)) +  geom_point(size=0.5) + 
  facet_wrap(~ Year)

# Prepare the spatial grid
source("../Processing/Get_grids_per_ME.R")
grid <- get_grid_ME(ME_name = ME_name, grid_size_km = 10)
grid$col <- ifelse(grid$Depth >= -500,"blue","red")
plot(grid$geometry, border = NA, col = grid$col, main = "10km Grid")
unique_hauls <- Reg[!duplicated(Reg$Haul_id), ]
points(unique_hauls$Longitude, unique_hauls$Latitude)
legend("bottomright",c("in","out"),pch=15,col=c("blue","red"),box.col = "white")

grid <- grid |> 
  rename(Longitude = lon, Latitude = lat) %>%  # Rename columns for clarity
  st_drop_geometry()      # Drop geometry for data manipulation

# Replicate the grid for each unique survey year
grid <- replicate_df(grid, "Year", min(Reg$Year):max(Reg$Year)) 

# Standardize the bottom depth for the grid
grid <- grid |> 
  mutate(log_depth = log(abs(Depth)),
         log_depth_std = (log_depth - mean(log(Reg$Bottom_depth))) / 
           sd(log(Reg$Bottom_depth)))

# Convert longitude and latitude to UTM coordinates
grid <- add_utm_columns(grid, c("Longitude", "Latitude"), units = "km")  
grid <- grid |> na.omit()

# Prepare the survey dataset
Reg <- Reg %>%
  mutate(Month = as.numeric(Month), 
    log_depth_std = scale(log(Bottom_depth))[, 1],  # Standardize bottom depth
    Yearf = as.factor(Year),  # Convert Year to factor
    Monthf = as.factor(Month) # Convert Month to factor
  )

# Convert longitude and latitude in survey data to UTM coordinates
Reg <- add_utm_columns(Reg, c("Longitude", "Latitude"), units = "km")

# now check if a model is already available
if (!file.exists(paste0("../Models_sdmtmb/stocks_",ME_name,".RData"))) {

  # get stocks biomass 
  Reg$stocks_kg_km2 <- Reg$dem_stock + Reg$pel_stock
  
  # get the data type to run the model
  data_type <- "stocks_kg_km2"
  
  # Substitute 0s with the minimum value registered
  # see table(Reg$stocks_kg_km2==0)
  #Reg[,data_type] <- ifelse(Reg[,data_type] == 0,
  #                            min(Reg[,data_type][Reg[,data_type] > 0]),
  #                            Reg[,data_type])
  
  # Create a spatial mesh for the data
  spatial_mesh <- make_mesh(Reg, c("X", "Y"), cutoff = 20)
    
  # Fit a spatial model using sdmTMB
  model_fit <- sdmTMB(
    stocks_kg_km2 ~ 0 + Yearf + (1|Monthf) + 
      poly(log_depth_std,2,raw = T), 
    data = Reg,                     
    mesh = spatial_mesh,                
    family = tweedie(link = "log"),   # good qq-plot, prefered over lognormal (AIC)
    spatial = "on",                   # Enable spatial random effects
    time = "Year",                    # Add spatiotemporal random effects
    spatiotemporal = "iid",           # iid independent, rw as a random walk
  )
  
  # Print model summary for diagnostics
  save(model_fit,file= paste0("../Models_sdmtmb/stocks_",ME_name,".RData"))

} else {
  load(paste0("../Models_sdmtmb/stocks_",ME_name,".RData"))
}

print(model_fit)  

# prepare grid for the prediction
grid$Yearf <- as.factor(grid$Year)
grid$Monthf <- as.factor(2)
grid <- subset(grid, abs(grid$Depth) < 500)

# Generate predictions using the fitted model and the grid
predictions <- predict(model_fit, newdata = grid, 
                       return_tmb_object = TRUE) #kg/km2

# make sure that output is back-transformed, if used spatially --> 
# predictions$data$est <- exp(predictions$data$est)
  
# Calculate the biomass index with bias correction
if (!file.exists(paste0("../Models_sdmtmb/Index_stocks_",ME_name,".RData"))) {
  bio_index <- get_index(predictions, area = 100, bias_correct = T)
  save(bio_index,file= paste0("../Models_sdmtmb/Index_stocks_",ME_name,".RData"))
} else {
  load(paste0("../Models_sdmtmb/Index_stocks_",ME_name,".RData"))
}
stck_index <- bio_index
stck_index$area <- length(grid$Year[grid$Year == Start_year]) * 100

plot(Bio_STO$Tbio/Bio_STO$area~Bio_STO$Year,ylim=c(0,45),type="l",col="black",
     lwd=2,ylab="tonnes km-2",las=1,xlab="Year",main="Biomass assessed stocks")
lines(Bio_STO$Tbio_low/Bio_STO$area ~ Bio_STO$Year,lwd=2,lty=3)
lines(Bio_STO$Tbio_high/Bio_STO$area ~ Bio_STO$Year,lwd=2,lty=3)

lines(stck_index$est/stck_index$area/1000~stck_index$Year,col="#228833",
      pch=16,lwd=2)
polygon(x = c(stck_index$Year,rev(stck_index$Year)), 
        y = c(stck_index$lwr/stck_index$area/1000,
              rev(stck_index$upr/stck_index$area/1000)),
        col = adjustcolor("#228833", 0.2),border=NA)
legend(Start_year,47, legend=c("Stock database", "Trawl survey"),
       col=c("black", "#228833"), lty=c(1,1), cex=1,y.intersp = 1,x.intersp = .5,
       seg.len=1,box.lty=0,bg="transparent")

```

## Total biomass

Time series of total fish biomass were estimated using data from scientific trawl surveys in a similar way as above but now for all species in the survey.

```{r Tot. biomass}
# -----------------------------------------------------
# continue with the above

# check if a model is already available
if (!file.exists(paste0("../Models_sdmtmb/total_",ME_name,".RData"))) {

  # get the data type to run the model
  data_type <- "Total_kg_km2"
  
  # Substitute 0s with the minimum value registered
  # see table(Reg$Total_kg_km2 == 0)
  Reg[,data_type] <- ifelse(Reg[,data_type] == 0,
                              min(Reg[,data_type][Reg[,data_type] > 0]),
                              Reg[,data_type])
  
  # Create a spatial mesh for the data
  spatial_mesh <- make_mesh(Reg, c("X", "Y"), cutoff = 20)
    
  # Fit a spatial model using sdmTMB
  model_fit <- sdmTMB(
    Total_kg_km2 ~ 0 + Yearf + (1|Monthf) + 
      poly(log_depth_std,2,raw = T), 
    data = Reg,                     
    mesh = spatial_mesh,                
    family = lognormal(link = "log"),        # Lognormal family
    spatial = "on",                        # Enable spatial random effects
    time = "Year",                         # Add spatiotemporal random effects
    spatiotemporal = "iid",                 # iid independent, rw as a random walk
  )
  
  # Print model summary for diagnostics
  save(model_fit,file= paste0("../Models_sdmtmb/total_",ME_name,".RData"))

} else {
  load(paste0("../Models_sdmtmb/total_",ME_name,".RData"))
}

print(model_fit)  

# grid is already prepared for the prediction

# Generate predictions using the fitted model and the grid
predictions <- predict(model_fit, newdata = grid, 
                       return_tmb_object = TRUE) #kg/km2

# make sure that output is back-transformed, if used spatially --> 
# predictions$data$est <- exp(predictions$data$est)
  
# Calculate the biomass index with bias correction
if (!file.exists(paste0("../Models_sdmtmb/Index_total_",ME_name,".RData"))) {
  bio_index <- get_index(predictions, area = 100, bias_correct = T)
  save(bio_index,file= paste0("../Models_sdmtmb/Index_total_",ME_name,".RData"))
} else {
  load(paste0("../Models_sdmtmb/Index_total_",ME_name,".RData"))
}
bio_index$area <- length(grid$Year[grid$Year == Start_year]) * 100

# make plot
plot(bio_index$est/bio_index$area/1000~bio_index$Year,ylim=c(0,100),type="l",col="#228833",lwd=2,
     ylab="tonnes km-2",las=1,xlab="Year",main="Total survey biomass")
polygon(x = c(bio_index$Year,rev(bio_index$Year)), 
        y = c(bio_index$lwr/bio_index$area/1000,
              rev(bio_index$upr/bio_index$area/1000)),
        col = adjustcolor("#228833", 0.2),border=NA)

```

## Exploitation rate

Time series of the fish community exploitation rate were estimated by dividing catches over total biomass. This was done using SAU and survey data, as well as, stock assessment information.

```{r Expl. rate}
# -----------------------------------------------------
plot(Catch_SAU$Tonnes/(bio_index$est/1000) ~ Catch_SAU$Year, 
     lty=2,lwd=2,col="red",type="l",ylab="yr-1",las=1,xlab="Year",
     main="Exploitation rate",ylim=c(0,1))

lines(Catch_WAT$Tonnes/(bio_index$est/1000) ~ Catch_WAT$Year,lty=3,lwd=2,col="blue")

ER_STO <- aggregate(cbind(Catch,Tbio)~Year,data=STO,FUN=sum)
ER_STO$ER <- ER_STO$Catch/ER_STO$Tbio

lines(ER_STO$ER~ER_STO$Year,lty=1,lwd=2,col="black")
legend(Start_year,1, legend=c("SAU/survey biomass","WAT/survey biomass",
                              "Stock database"),
       col=c("red", "blue", "black"), lty=c(2,3,1),
       cex=1,y.intersp = 1,x.intersp = .5,
       seg.len=1,box.lty=0,bg="transparent")


```

## Percentage of demersal fish

The proportion of demersal fish can serve as a calibration point for models incorporating different functional groups. This proportion can be derived from both catch statistics and scientific survey data. However, bottom trawl surveys likely underestimate the abundance of pelagic fish, a bias that is partly addressed by assuming lower catchability for these species.

```{r perc_demersal}
# -----------------------------------------------------
# get it for SAU
peltype <- c("Small pelagics (<30 cm)","Medium pelagics (30 - 89 cm)",
              "Large pelagics (>=90 cm)","Small bathypelagics (<30 cm)",
             "Medium bathypelagics (30 - 89 cm)","Large bathypelagics (>=90 cm)")
pel_SAU <- subset(SAU,SAU$functional_group %in% peltype)
pel_SAU <- aggregate(tonnes~year,data=pel_SAU,FUN=sum)
colnames(pel_SAU) <- c("Year","Tonnes")
dem_SAU <- subset(SAU,!(SAU$functional_group %in% peltype))
dem_SAU <- aggregate(tonnes~year,data=dem_SAU,FUN=sum)
colnames(dem_SAU) <- c("Year","Tonnes")
pcdem_SAU <- dem_SAU$Tonnes/ (pel_SAU$Tonnes + dem_SAU$Tonnes) * 100

# get if for Watson
pcdem_WAT <- WAT$Catch_dem/ (WAT$Total_catch) * 100

# get it for the survey - shortcut
load("../Data/Trawl_survey/Surveys_hauls_species_LMEs_MEs.RData")
Reg <- subset(trawl,trawl$ME == ME_name & 
                trawl$Year %in% Start_year:End_year)
Reg$F_type <- ifelse(Reg$Name=="Sebastes mentella","pel",Reg$F_type) # to match with SAU
pel_SUR <- subset(Reg,Reg$F_type == "pel")
pel_SUR <- aggregate(kg_km2_corrected~Year,data=pel_SUR,FUN=sum)
colnames(pel_SUR) <- c("Year","kg_km2_corrected")
dem_SUR <- subset(Reg,Reg$F_type == "dem")
dem_SUR <- aggregate(kg_km2_corrected~Year,data=dem_SUR,FUN=sum)
colnames(dem_SUR) <- c("Year","kg_km2_corrected")
pcdem_SUR <- dem_SUR$kg_km2_corrected/ (pel_SUR$kg_km2_corrected +
                                          dem_SUR$kg_km2_corrected) * 100


plot(pcdem_SAU~dem_SAU$Year,ylim=c(0,100),type="l",col="red",
     lwd=2,lty=2,ylab="%",las=1,xlab="Year", main="% demersal in total fish")
lines(pcdem_WAT~WAT$Year,lty=3,lwd=2,col="blue")
lines(pcdem_SUR~dem_SUR$Year,lty=1,lwd=2,col="black")
legend(Start_year,35, legend=c("SAU (catch)", "Watson (catch)", "Trawl sur. (biomass)"), col=c("red", "blue","black"), lty=c(2,3,1), cex=1,y.intersp = 1,x.intersp = .5,seg.len=1, box.lty=0,bg="transparent")


```

## Data output

A .csv file is created with all data outputs. Abbreviations: SAU = Sea Around Us, WAT = Watson (2017), SUR = scientific bottom trawl survey data, STO = ICES stock assessment database.

```{r csv output}
# -----------------------------------------------------
# make dataframe with all information

dat <- data.frame(Region=ME_name,
           Year=Catch_SAU$Year,
           Catch_SAU_tonnes = Catch_SAU$Tonnes,
           Catch_WAT_tonnes = Catch_WAT$Tonnes,
           Catch_STO_tonnes = Catch_STO$Tonnes,
           Land_SAU_tonnes = Land_SAU$Tonnes,
           Land_WAT_tonnes = Land_WAT$Tonnes,
           Land_STO_tonnes = Land_STO$Tonnes,
           Stckbio_lwr_STO_MTkm2 = Bio_STO$Tbio_low/Bio_STO$area,
           Stckbio_STO_MTkm2 = Bio_STO$Tbio/Bio_STO$area,
           Stckbio_upr_STO_MTkm2 = Bio_STO$Tbio_high/Bio_STO$area,
           Stckbio_lwr_SUR_MTkm2 = stck_index$lwr/stck_index$area/1000,
           Stckbio_SUR_MTkm2 = stck_index$est/stck_index$area/1000,
           Stckbio_upr_SUR_MTkm2 = stck_index$upr/stck_index$area/1000,
           Tbio_lwr_SUR_MTkm2 = bio_index$lwr/bio_index$area/1000,
           Tbio_SUR_MTkm2 = bio_index$est/bio_index$area/1000,
           Tbio_upr_SUR_MTkm2 = bio_index$upr/bio_index$area/1000,
           ER_SAU_SUR = Catch_SAU$Tonnes/(bio_index$est/1000),
           ER_WAT_SUR = Catch_WAT$Tonnes/(bio_index$est/1000),
           ER_STO = ER_STO$ER,
           pcdem_SAU = pcdem_SAU,
           pcdem_WAT = pcdem_WAT,
           pcdem_SUR = pcdem_SUR)

write.csv(dat, paste0("../Outputs-by-region/",ME_name,".csv"),row.names = F)
           
```
